{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada507fc-7090-4973-bbac-35bca7792092",
   "metadata": {},
   "source": [
    "# Advanced Pandas Assignment 3\n",
    "\n",
    "In this assignment, you will practice cleaning \"dirty\" data.\n",
    "\n",
    "### Note about assignments\n",
    "You can add lines of code according to your preferences. As long as the code required by the assignment is found in this notebook under the corresponding question header (ie. the answer to question 1 is underneath the title \"Question 1\"), you will receive credit for it.\n",
    "\n",
    "## About the data\n",
    "The data used in this assignment is a table built from the Human Resources schema of the Adventure Works 2019 database. This data contains information about each time that Employee Pay History was changed (each line is a pay rate change). It also contains information about the employee and the department they were working in when they received the pay rate listed.\n",
    "\n",
    "This data is similar to data used in previous assignments but has been \"dirtied\" in order to make this assignment possible. \n",
    "\n",
    "The actual data is stored in a CSV file located inside the `data` folder. The file is called `pay_history.csv`.\n",
    "\n",
    "## Instructions\n",
    "### Set up\n",
    "##### Import Pandas\n",
    "Import the Pandas library into Jupyter Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa476f-ffe2-432a-a8bd-5e18d96177e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd4794-0c3f-42cd-8879-5e075d16a1b2",
   "metadata": {},
   "source": [
    "##### Disable column display limit\n",
    "Use the following code to disable the default limit for displaying columns. If you don't use this code, a data set with more than 20 columns will be truncated when displayed to take up less space.\n",
    "\n",
    "```\n",
    "pd.options.display.max_columns = None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683c034-4cc4-4ebd-bd4b-54b854474a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c8157-546c-4c8c-86ea-ea00e8bf9d41",
   "metadata": {},
   "source": [
    "##### Create the dataframe\n",
    "Use the `read_csv()` function from Pandas to read the data from the `pay_history.csv` file into a dataframe called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9e3fc3-6f85-4e97-8f86-6b91f7bf89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/pay_history.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64b4b7-25fd-49f0-bb1d-ab92509284e7",
   "metadata": {},
   "source": [
    "##### Preview dataframe\n",
    "Use the `.head()` method to print out the first 5 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc6e4c-5445-4ce4-9082-020562637fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c03f79-28e9-46cd-9ac6-924a2323071a",
   "metadata": {},
   "source": [
    "### Questions\n",
    "The data you were given to analyze looks perfectly normal at first glance. However, knowing that humans are imperfect at inputting data, you decide to do a quick glance over the data to make sure that nothing strange is happening. If there are mistakes in the data, you are determined to fix them in such a way that they don't affect the analysis.\n",
    "\n",
    "\n",
    "#### Find Null Values\n",
    "##### Question 1: Describe the data \n",
    "Before anything else, use the `.info()` method to check the count of null values in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae33476-4b17-44df-8e4c-b116611e45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24734f-5640-4d8d-90cc-0e0dc375f45d",
   "metadata": {},
   "source": [
    "##### Question 2: Count null values\n",
    "Use the `.isna()` method in conjunction with the `.sum()` method to get a count of null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38fab0-9e53-4658-888b-784af4ae904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c262a1-12f3-42ce-a6f3-40605124df3f",
   "metadata": {},
   "source": [
    "##### Question 3: Which columns have null values?\n",
    "Which columns have null values? What do you think should be done to these columns to prepare the data set for analysis (imputation or drop the column)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b1cf7-7350-4c22-bf84-3a11605c448c",
   "metadata": {},
   "source": [
    "1. Rate - Imputation\n",
    "2. OrganizationLevel - Imputation\n",
    "3. SalariedFlag - Drop Column\n",
    "4. EndDate - Drop Column\n",
    "5. Sub-Department - Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e75f29-b522-422d-9bdf-1d81beede64f",
   "metadata": {},
   "source": [
    "#### Rate - Imputation (part 1)\n",
    "Because there are only two missing values in the `Rate` column, let's try to impute them. We can start to do this by discovering the average rate and then assigning it to both rows where `Rate` is null.\n",
    "\n",
    "##### Question 4: Select the `Rate` column\n",
    "Get the `Rate` column out of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d534b1f-063f-428f-9bb1-07a3f7ece99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765a775-d10c-41c5-bd77-03fede62de3f",
   "metadata": {},
   "source": [
    "##### Question 5: Get the average rate\n",
    "Use the `.mean()` method to get the average rate and save it to a variable `average_rate`. Print it out to show what the average rate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2053c296-94e3-4929-81d7-bdb5cfe2a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rate = df['Rate'].mean()\n",
    "average_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74939c67-2d6f-442d-843f-2f2603c2a71d",
   "metadata": {},
   "source": [
    "##### Question 6: Get the rows where `Rate` is null\n",
    "Use the `.isna()` method with the `.loc` property to create a filter that returns rows where `Rate` is null. Show these rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3618c-37e5-41d6-907f-908660a9cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['Rate'].isna() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f60a5-ee4a-4b56-8da8-76c70c877510",
   "metadata": {},
   "source": [
    "##### Question 7: Get the indexes of the null rows\n",
    "Use the `.index` property to get the indexes from the filtered dataframe and save them to a variable `null_rates`. Print out this variable as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27165e8-8fba-45d7-9379-7dd02547900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rates = df[ df['Rate'].isna() ].index\n",
    "null_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56901439-cdce-4635-8c72-334f270ce454",
   "metadata": {},
   "source": [
    "##### Question 8: Get `Rate` column of filtered dataframe\n",
    "Using the filtered dataframe from above (Question 6), get the `Rate` column by adding `Rate` to the `.loc` property.\n",
    "\n",
    "You should get two rows back in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f91454-264d-4763-9e04-1c62999e6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['Rate'].isna(), 'Rate' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fdb58e-1f05-4696-9709-50b7439f506a",
   "metadata": {},
   "source": [
    "##### Question 9: Set null rows equal to overall average rate\n",
    "Using the code from the previous question, set the `Rate` of the two rows with null rates equal to the `average_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafbdaf4-8312-43ff-bfa1-997c4d082e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['Rate'].isna(), 'Rate' ] = average_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97313bad-3ee1-4d14-9f86-f9263ee293cc",
   "metadata": {},
   "source": [
    "##### Question 10: Print out the number of nulls\n",
    "Using the code from Question 2, print out the number of null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc25b73-ac69-4c32-8181-36595714f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971d8ea-5273-437e-beac-227754ec0e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Rate - Imputation (part 2)\n",
    "##### Question 11: Is the overall average `Rate` the best?\n",
    "Now we can see that the overall average `Rate` was successfully imputed into the null values for each `Rate`. However, is this `Rate` an accurate reflection of what the `Rate` likely actually is for both employees? What could be done to estimate the rate more accurately?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe32df-02a4-4528-a450-3a42d11d46cf",
   "metadata": {},
   "source": [
    "```\n",
    "The overall average rate might be completely different from the actual average rate for each employee. Production Technicians and Sales Representatives might make more or less than the average employee. A more accurate representation of the actual likely rate for each one could be found by grouping the employees by department or job title and THEN finding the average rate in that group.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b745333-1dfd-4b1f-9124-723b9598c417",
   "metadata": {},
   "source": [
    "##### Question 12: Get `JobTitle` of each (previously) null row\n",
    "Using the `.loc` property and the `null_rates` list of indexes that you obtained previously, print out the `JobTitle` column (a Series) for each of the rows which previously had a null value for `Rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bafd3-8a70-4eca-b7d8-17a6e2085634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[null_rates, 'JobTitle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d435e-f09b-408d-970b-41914b60283b",
   "metadata": {},
   "source": [
    "##### Question 13: Turn the Series into a list\n",
    "Add the `.tolist()` method onto the previous line of code to place the two job titles into a list. Save this list of job titles into a variable `job_titles` and then print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d09f67-90c8-4e9d-a86b-6f5591670027",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = df.loc[null_rates, 'JobTitle'].tolist()\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929da38a-70f4-4c12-a1c6-9a7b47517d4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Question 14: Filter the dataframe by `job_titles`\n",
    "Using the `.isin()` method and the `.loc` property, get back all rows of the dataframe that have a value in the `JobTitle` column that exists in the `job_titles` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373c75d-e37b-4a38-8db1-159be7236fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[ df['JobTitle'].isin(job_titles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abea15-08b7-452d-9f8d-b63b2e1b9fdb",
   "metadata": {},
   "source": [
    "##### Question 15: Observe the filtered dataframe above\n",
    "Observe the filtered dataframe returned above. What do you notice about the average rate of pay for the different job titles? How are they different from the overall average rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb78af2-8fb8-47d8-a71e-e4675ebd4ff9",
   "metadata": {},
   "source": [
    "```\n",
    "The overall average rate was $17.67. However, the average rate for a Product Technician is $15, and the average rate for a Sales Representative is $23.08. Thus, there is a fairly significant difference from the actual rates of people with those job titles and the overall average rate.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e612753-143e-4146-84fd-338dd4f7498a",
   "metadata": {},
   "source": [
    "##### Question 16: Group by `JobTitle` and find the mode\n",
    "Using the `.groupby()` and `.agg()` methods, group the filtered dataframe from question 13 by `JobTitle` and aggregate to find the most common value for `Rate`.\n",
    "\n",
    "Note: Pandas doesn't have a built in aggregate function to find the mode using `.agg()`. Thus, the code `.agg({'Rate': 'mode'})` won't work. Instead, you'll have to use the Pandas Series method, which will look like this: `.agg({'Rate': pd.Series.mode})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a02d74-a79c-4e5a-9fac-980bff2808ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['JobTitle'].isin(job_titles)].groupby('JobTitle').agg({'Rate': pd.Series.mode})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fa952-33e6-4d44-83f6-475162829436",
   "metadata": {},
   "source": [
    "##### Question 17: Replace overall rates with average rate by job title\n",
    "Using any way you would like, replace both of the (previously) null rates that were assigned the overall average rate a more precise average rate based on their `JobTitle`. You can either do this by using the `.loc` property and the indexes created before, or by using the `.loc` property with a filter by average `Rate` and a specific `JobTitle`.\n",
    "\n",
    "It will be easiest to do this on more than one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67610873-c09d-41de-b966-4a38a5e64693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the index created previously\n",
    "df.loc[ null_rates[0], 'Rate'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c386f1e-d38f-4c72-9f6f-9ac9f7372c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a filter\n",
    "df.loc[ (df['Rate'] == average_rate) & (df['JobTitle'] == 'Sales Representative'), 'Rate' ] = 23.0769"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37f1eb-6729-45ef-9c01-cde627d55923",
   "metadata": {},
   "source": [
    "##### Question 18: Print out number of nulls\n",
    "Using the `.isna()` and the `.sum()` methods, show how many null values exist in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c86d1a-ef24-48b8-bb49-3ebbe6721dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1249f-27f0-45d9-85ac-96916cbad80b",
   "metadata": {},
   "source": [
    "#### SalariedFlag - Drop Column\n",
    "The columns `SalariedFlag` and `EndDate` seem to have many null values. In a way, it makes sense that there might be null values in the `EndDate` column, since the database designers may have designed the system so that it doesn't record any value until an employee actually stops working at Adventure Works. However, the `SalariedFlag` field is a little more suspicious.\n",
    "\n",
    "Most likely, we will end up dropping the `SalariedFlag` column because there are so many null values. However, let's make sure to look at it first to make sure that we *can't* impute it (ie. if we can see that all of the recorded values are the same, we might be able to justify imputation in specific situations).\n",
    "\n",
    "##### Question 19: Print out counts of each unique value in `SalariedFlag`\n",
    "Before anything else, we should check to see the counts of distinct values in the `SalariedFlag` column. Use the `.value_counts()` method to print this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee078a2b-3cc2-40fe-a82a-471cbd1c83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalariedFlag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d4e71-b5c5-4c63-849c-092ebfe949b3",
   "metadata": {},
   "source": [
    "##### Question 20: What do you see when counting the distinct values?\n",
    "Upon observing the count of distinct values in the `SalariedFlag` column, what do you notice? Is there any way we could possibly justify imputation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816adf3c-b05d-40a3-99d7-2507945cd9c0",
   "metadata": {},
   "source": [
    "```\n",
    "The counts of 1 and 0 are almost evenly split. It would be impossible to determine which rows should have a 1 or 0 without further evidence. For this reason, imputation cannot be used and the column should be dropped.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c02d7e-ee42-4d76-81bd-b578077e5b8d",
   "metadata": {},
   "source": [
    "##### Question 21: Drop the `SalariedFlag` column\n",
    "Use the `.drop()` method to drop the `SalariedFlag` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478662e-8405-4451-b1bb-dbeded5c9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='SalariedFlag', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713962f1-4d27-473b-a9ae-9d862f1449de",
   "metadata": {},
   "source": [
    "##### Question 22: Print out the number of nulls\n",
    "Use the `.isna()` and `.sum()` methods to show how many null values still exist in the dataframe. Make sure that the column `SalariedFlag` has been dropped successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfff92e-3b57-4a5f-8513-aa476c376269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8617d-a31d-48a7-bc33-2648e7ea5f8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Check inconsistent format\n",
    "To make sure that each of our columns has data in a consistent format, we should check to make sure that each column has the data type that we expect. If all of the quantitative fields are either `int64` or `float64`, we can move on to the categorical fields and get a count of each unique value to make sure each row has an expected value.\n",
    "\n",
    "##### Question 23: Check for data types of quantitative fields\n",
    "Use the `.info()` method to check the data types of each column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e5f0e-4472-44b8-acec-d40e509e732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45de0b5-dfef-49d9-a8f2-1dec29478080",
   "metadata": {},
   "source": [
    "##### Question 24: Does any column surprise you?\n",
    "Looking at the information printed above and knowing a little about the data, do any of the column data types surprise you? Which column(s) surprise you and why? (yes, there should be at least one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8d678-a0cf-4f5e-8bff-8d46058ff923",
   "metadata": {},
   "source": [
    "```\n",
    "From what I have seen in previous data, the `CurrentFlag` column should be either a 1 or a 0 and thus have a Dtype of `int64`. However, it has a Dtype of `object`. Thus, I think that a string must have gotten introduced into the column's data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1cf04-6c75-4688-941a-ebfc0805eb9f",
   "metadata": {},
   "source": [
    "##### Question 25: Check count of values of `CurrentFlag`\n",
    "To be sure that there are issues with the `CurrentFlag` column, print out the count of unique values in the column using the `.value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8970bf-bfd6-4e7c-b0d8-7b1766d6dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CurrentFlag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6040f-65da-480e-9491-14b5c9680785",
   "metadata": {},
   "source": [
    "##### Question 26: What do you observe?\n",
    "After counting up each unique value in the `CurrentFlag` column, what do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16afb4cb-e808-4143-a9f8-49f04b49dc65",
   "metadata": {},
   "source": [
    "```\n",
    "There is a mix of 1s and the word \"yes\", which probably should have been 1s.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eea7aa-b77a-4900-bbc2-90e978c394a1",
   "metadata": {},
   "source": [
    "##### Question 27: Get rows where `CurrentFlag` is `yes`\n",
    "Filter the dataframe using `.loc` to show only rows where `CurrentFlag` is equal to `\"yes\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bd7c0-6ad4-44eb-a6f0-50f3064befba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['CurrentFlag'] == \"yes\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95040c-6f19-4d8b-ad7a-4e3de9631747",
   "metadata": {},
   "source": [
    "##### Question 28: Change each `\"yes\"` to `1`\n",
    "It's probably safe to assume that, since all of the values in the `CurrentFlag` column are either `1` or `\"yes\"`, all `\"yes\"` values can be changed to 1. Use the `.replace()` method to replace all occurences of \"yes\" with **the integer** `1`. Save it to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5d2e2-1956-48f4-a390-6a8cc1d24923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CurrentFlag'].replace(\"yes\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d20385-0eed-46dc-821e-507343f724c8",
   "metadata": {},
   "source": [
    "##### Question 29: Print out the value counts again\n",
    "Use the `.value_counts()` method to print out the counts of unique values in the `CurrentFlag` again. Make sure that the only value that occurs now is `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7448f-945e-468f-b799-33145b2eeef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CurrentFlag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab7b934-92c9-48d9-a4e1-630997e52918",
   "metadata": {},
   "source": [
    "##### Question 30: What do you notice?\n",
    "What do you notice about the results of the results of `.value_counts()`? Why do you think this occured?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51d1a2-4f31-4db7-90bb-a694005ded8a",
   "metadata": {},
   "source": [
    "```\n",
    "The value `1` is counted twice as if there were two types of `1`. It must be because the first `1` is a string and the second `1` is an integer and so they are different.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31776de4-4d86-4451-a6d7-58c411cdd369",
   "metadata": {},
   "source": [
    "#### Fix not matching data type\n",
    "It looks like because the column `CurrentFlag` started out with strings inside of it, most of its values are still of data type `object`. Change it so that the `CurrentFlag` column has a data type of `int8`.\n",
    "\n",
    "##### Question 31: Print out the data type of `CurrentFlag`\n",
    "Using the `.dtype` property, print out the data type of the `CurrentFlag` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d0ccf-38a1-4c09-8826-acbfc1eb268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CurrentFlag'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00144ff-c64e-452b-824d-b70a7077a9f1",
   "metadata": {},
   "source": [
    "##### Question 32: Create `CurrentFlag` as data type `int8`\n",
    "Using the `.astype()` method, print out a copy of the `CurrentFlag` column whose data type is `int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6845bd-943a-427c-8c9f-b3cb7e22e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CurrentFlag'].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a795c-a776-412f-97f2-18e558575ea7",
   "metadata": {},
   "source": [
    "##### Question 33: Override the `CurrentFlag` column\n",
    "Using the code from above, save the new `CurrentFlag` column of data type `int8` to the `CurrentFlag` column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba4a0d-8220-4364-9d85-717459f7c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CurrentFlag'] = df['CurrentFlag'].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463a0f9-61f2-4ee8-9d39-6ff21f50e578",
   "metadata": {},
   "source": [
    "##### Question 34: Print out the dataframe info\n",
    "Use the `.info()` method to print out information about the data types of each column. Make sure that the `CurrentFlag` column now has a data type of `int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fee2a5-57ac-4f4c-9a12-1895dc3a9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2f1c7-96f2-4d43-98ec-2b0ce6cb5b3e",
   "metadata": {},
   "source": [
    "#### Fix Extreme Values\n",
    "While you have already fixed some columns with null values and incorrect values. Now, let's check the data set for extreme/incorrect values.\n",
    "\n",
    "##### Question 35: Describe the dataframe\n",
    "Use the `.describe()` method on the dataframe to get some summary statistics about each quantitative row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea070bda-2c66-4fe5-ad22-512ed7d0c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f4235-e8c9-4183-b4ff-27f9b1e0ad49",
   "metadata": {},
   "source": [
    "##### Question 36: What do you notice?\n",
    "Observe the information created by the `.describe()` method above. What do you notice about the summary statistics that might indicate inaccurate data? You should see at least two columns with potential problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc873464-4384-4190-96dc-9d05f5152a44",
   "metadata": {},
   "source": [
    "```\n",
    "The `Rate` column has negative values, which is impossible and should be further investigated. The `VacationHours` column also has a very high maximum value and might be an error.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af911b9-1c66-486b-a07b-5ef0941f2f56",
   "metadata": {},
   "source": [
    "#### Fix Rate\n",
    "##### Question 37: Get a filtered `Rate` column\n",
    "Knowing that the `Rate` column has at least one negative number, create a filtered dataframe that contains rows where `Rate` is less than or equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f773f38-9d5b-4a68-9a50-75471d638233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['Rate'] <= 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333b351-702f-4a4c-91b7-56ee8e5907de",
   "metadata": {},
   "source": [
    "##### Question 38: What should be done?\n",
    "Looking at the row(s) returned, what do you think should be done? Can the true `Rate` of the rows with negative values be imputed, or should they be dropped?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5386c-9c19-4faa-858d-26f8d0746fb0",
   "metadata": {},
   "source": [
    "```\n",
    "The `JobTitle` of the only row returned is Vice President of Sales, which makes me expect a higher rate. Simply making the `Rate` positive rather than negative makes sense to me.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2d6b2-df99-467d-92de-08e8bb4485b5",
   "metadata": {},
   "source": [
    "##### Question 39: Make the negative `Rate` positive\n",
    "Using the code from above, print out a the `Rate` column of rows whose `Rate` is less than or equal to 0. Multiply it by `-1` to make it positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd4f50-cff3-400f-8191-7cea72f56834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['Rate'] <= 0, 'Rate' ] * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f384e-1dc8-4b00-b9d4-b4530f9aaea8",
   "metadata": {},
   "source": [
    "##### Question 40: Set the negative rate to positive rate\n",
    "Using the code from above, filter the dataframe to get negative rates and set the new rates equal to the negative rate times `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a05cfd-bc1e-4500-9ac9-3afef8adf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['Rate'] <= 0, 'Rate' ] = df.loc[ df['Rate'] <= 0, 'Rate' ] * -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4a2b1-c4dc-4fa9-8ce6-c6e428b3f66d",
   "metadata": {},
   "source": [
    "##### Question 41: Print out the dataframe description again\n",
    "Use the `.describe()` method to print out the dataframe description again. Make sure that the minimum rate is greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470b6c4-54b1-4a87-bc30-482295aefe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57960054-eed8-405b-8881-f5198beebacb",
   "metadata": {},
   "source": [
    "#### Fix VacationHours\n",
    "The maximum value in the `VacationHours` is 290-- that might be correct, but it also might be out of the ordinary. Let's do some work to try and fix it.\n",
    "\n",
    "##### Question 42: Sort the dataframe by `VacationHours` descending\n",
    "Use the `.sort_values()` method and the `by` and `ascending` arguments to print out the dataframe sorted by `VacationHours`, with the rows with the highest number of vacation hours on top. Add the `.head()` method after the `.sort_values()` method to get the top five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f16b68-c8b7-4510-8f72-fb04e1cdbbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='VacationHours', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead8dfb0-fbe4-4139-a329-9e150462b2b6",
   "metadata": {},
   "source": [
    "##### -- Check if outlier\n",
    "##### Question 43: Import numpy\n",
    "Before anything else, let's test to see whether `290` is really an outlier for the `VacationHours` column. To begin, import the NumPy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a28a0-c184-45aa-be45-f4c050ccfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8557a-be23-4f60-8658-724641a9b359",
   "metadata": {},
   "source": [
    "##### Question 44: Create function `isOutlier()`\n",
    "Now create a function called `isOutlier()` that accepts one parameter `hours`. The function will be applied to each row of the `VacationHours` column and should perform the following:\n",
    "\n",
    "1. Uses the `np.quantile()` function on the `VacationHours` column to get the first quartile (`0.25`) and save it to a variable `first_quartile`.\n",
    "2. Uses the `np.quantile()` function on the `VacationHours` column to get the third quartile (`0.75`) and save it to a variable `third_quantile`.\n",
    "3. Subtracts the `first_quartile` from the `third_quartile` and saves the results to a variable `iqr` (inner-quartile range).\n",
    "4. Calculates the upper fence by performing `third_quartile + (1.5 * iqr)`, saving it to a variable `upper_fence`.\n",
    "    - The upper fence is the upper limit for identifying outliers. Anything greater than the upper fence is considered an outlier.\n",
    "5. If `hours` is greater than the `upper_fence`, return `True` (the hours for this row *is* an outlier). Otherwise, return `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1965f479-8c95-4b5f-9292-3a2542ec3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isOutlier(hours):\n",
    "    # Get 25th percentile\n",
    "    first_quartile = np.quantile(df['VacationHours'], 0.25)\n",
    "    # Get 75th percentile\n",
    "    third_quartile = np.quantile(df['VacationHours'], 0.75)\n",
    "    # Get inner quartile range\n",
    "    iqr = third_quartile - first_quartile\n",
    "    # Calculate upper fence\n",
    "    upper_fence = third_quartile + (1.5 * iqr)\n",
    "    \n",
    "    if hours > upper_fence:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b843f6a-9d68-4e6f-b71f-5cc0985efdb0",
   "metadata": {},
   "source": [
    "##### Question 45: Apply function to the `VacationHours` column\n",
    "Using the `.apply()` method, pass in the `isOutlier` function without parentheses to return a Series of True/False values. True indicates a row where `VacationHours` is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed998b-b81b-4879-b1c9-9628d8805148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VacationHours'].apply(isOutlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091607bb-413e-4d49-a11e-93e1bd0440ee",
   "metadata": {},
   "source": [
    "##### Question 46: Save the Series above to a new column called `VacationHoursOutlier`\n",
    "Using the code from above, create a new column in the dataframe called `VacationHoursOutlier` that has either a True or False if the `VacationHours` is an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197f5d6-c7b9-4891-aba3-439a7312bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VacationHoursOutlier'] = df['VacationHours'].apply(isOutlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1620b00-3f0c-4eac-a888-31fa391a0858",
   "metadata": {},
   "source": [
    "##### Question 47: Sort the dataframe by `VacationHours` descending again\n",
    "In the same way that you did previously, use the `.sort_values()` method with the `by` and `ascending` arguments to view the rows with the highest number of `VacationHours`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e992c-ab77-4a55-b61c-5c9e24b81a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='VacationHours', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79d3c6-3132-4776-ad41-589dedc7a4fc",
   "metadata": {},
   "source": [
    "##### Question 48: Is `290` an outlier for `VacationHours`?\n",
    "Looking at the dataframe returned above, is `290` an outlier in the `VacationHours` column? If so, what could be done to fix this value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a1d08-97c3-4844-a575-1884cd619da8",
   "metadata": {},
   "source": [
    "```\n",
    "The number `290` is an outlier in the `VacationHours` column. This row could be dropped, or we could use imputation to determine what other employees with the same job title have as their `VacationHours` and assign an average value to the row.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a9da4-0dbb-45a0-a015-7500ab8e978e",
   "metadata": {},
   "source": [
    "##### Question 49: Get rows of employees with `JobTitle` Sales Representative\n",
    "As seen above, the row with total `VacationHours` has a `JobTitle` of \"Sales Representative\". Use a filter to get back rows of employees whose `JobTitle` is also \"Sales Representative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15001bdd-5a59-4dd2-88bb-04ba36b6a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['JobTitle'] == 'Sales Representative' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c15b3a-035e-4bef-a5ee-a87b30c75765",
   "metadata": {},
   "source": [
    "##### Question 50: Remove the row with outliers from the filter\n",
    "Add to the filter that you created above so that the row with an outlier in the `VacationHours` field is not included in the filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861f1fb-6445-4c65-8230-076807f1e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ (df['JobTitle'] == 'Sales Representative') & (df['VacationHours'] != 290) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a54c4-d166-4fab-bd7b-2247477a7a1f",
   "metadata": {},
   "source": [
    "##### Question 51: Get the average vacation hours among Sales Representatives\n",
    "Using the filtered dataframe above, get the average `VacationHours` for Sales Representatives. Store this number in a variable called `sales_rep_average_vac_hours` and then print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43281e5-e6c9-4229-be31-639b944ee1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_rep_average_vac_hours = df.loc[ (df['JobTitle'] == 'Sales Representative') & (df['VacationHours'] != 290), 'VacationHours' ].mean()\n",
    "sales_rep_average_vac_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1637a-d364-46e2-a2f3-5a40772078b0",
   "metadata": {},
   "source": [
    "##### Question 52: Assign the average vacation hours to the employee with an outlier `VacationHours`\n",
    "Using the `.loc` property, change the `VacationHours` of the employee with an outlier in the `VacationHours` column to be `sales_rep_average_vac_hours` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e810df9-be8d-4fbf-a518-dc9b1ed4cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ df['VacationHoursOutlier'], 'VacationHours'] = sales_rep_average_vac_hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9871c08-b807-4051-a41f-24d384b3890f",
   "metadata": {},
   "source": [
    "##### Question 53: Print out the dataframe description\n",
    "Finally, print out the dataframe description using the `.describe()` method. Make sure the maximum value for `VacationHours` is no longer 290."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56e118-dff5-480b-ad84-473033c96425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd670a-f9f5-4508-b4ac-4d31a9ce14ff",
   "metadata": {},
   "source": [
    "#### Final Thoughts\n",
    "In case you were curious, the value of the row with an outlier in `VacationHours` was originally `29` instead of `290`. That means that the error was most likely caused by a human who accidentally entered in an extra `0` on the end of the actual number. In any case, the average vacation hours among Sales Representatives turned out to be fairly close to this (`31.15`), meaning that imputation worked fairly well in this example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
