{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc0488-5fe0-4b47-9ff1-21dc931c9351",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3.3 Grouping and Aggregating Data\n",
    "\n",
    "The ability to group and aggregate data is one of the most powerful features of Pandas. Using the aggregation functionality allows analysts to quickly compute summary statistics over their data set at varying levels of specificity that they can choose. Aggregation in Pandas includes calculations such as `count`, `nunique` (distinct count), `sum`, `mean`, `median`, `mode`, `max`, `min` and `std` (standard deviation), among others.\n",
    "\n",
    "Grouping and aggregating in Pandas is based on the same principles as grouping and aggregation in SQL. In SQL, you would SELECT an aggregate function and then GROUP BY all of the non-aggregate columns. In Pandas, we just have to worry about which columns to group by and which columns to aggregate.\n",
    "\n",
    "Groups and aggregations are almost always used together. They allow the data analyst to \"drill down\" into sub-categories of the data and view trends between and within groups.\n",
    "\n",
    "### About the data\n",
    "\n",
    "The data used in this notebook shows information about passengers on the *Titanic* cruiseliner, a ship which set out from Southampton, U.K. to sail across the Atlantic ocean and which tragically sank upon collision with an iceberg. The dataset contains information about each passenger's passenger class, name, sex, age, siblings, parents/children, ticket number, ticket fare, cabin number, and the embarked location. It also contains information about each passenger's survival status. This data set is extremely popular among data scientists and will facilitate demonstrations of Pandas concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f22b5d-2632-4bde-898b-a348bb2f14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb05bb-6323-4add-9ec9-a60e15ba3073",
   "metadata": {},
   "source": [
    "### Groups\n",
    "In order to perform aggregation, Pandas needs to know how to group the data. In SQL, we used the GROUP BY clause to explicitly tell the query how to group the aggregations. In this *Titanic* data set, for example, we could group by passenger class (Pclass), where the person embarked (Embarked), or whether or not the person survived (Survived). In Pandas, we can actually perform an aggregation on the entire dataframe at once without specifying a group, and Pandas will just assume that the whole dataset is one big group.\n",
    "\n",
    "However, it is also important to specify how the rows should be grouped when they are aggregated. Below you will see how to aggregate on a dataframe without grouping AND will also see how to create groups that can then be aggregated.\n",
    "\n",
    "### Using aggregate functions on an entire dataframe\n",
    "Previously, we applied aggregate functions to an entire dataframe or Series object by using methods such as `.max()`, `.mean()`, and `.sum()`. As stated before, all aggregate functions need to be grouped before they can be processed. So, what are the groups when we use an aggregate function on an entire dataframe?\n",
    "\n",
    "Simply enough, the aggregate function treats the entire dataframe as one big group. Thus, there is no need to create groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f712dbc-dd9d-4c49-b752-05c046ed7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129bfc04-766c-4d1b-9a1d-9d407f5694aa",
   "metadata": {},
   "source": [
    "The code above `df.sum()` returned a Series object with all of the rows added/concatenated together. Some of the information is useful (like knowing that 342 people survived the Titanic), but other information is not as useful (like the total age being 21,205... what does that even mean?). Other information is completely useless (such as the total \"Sex\" being \"malefemalefemalefemalemale...\").\n",
    "\n",
    "In this way, we see that aggregating across an entire dataframe *can* be useful when you don't know much about your data and need quick information, but it's probably better to choose which columns to aggregate and which groups to create. This will allow you to obtain detailed information about specific groups. Grouping also allows you to control how aggregations are applied multiple groups at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b1b6e-afcf-4a73-b3d2-ef3e5409c579",
   "metadata": {},
   "source": [
    "### Creating a group by object\n",
    "Before applying an aggregate function to groups in a dataframe, Pandas first requires the creation of a `groupby` object. This can be done by using the `.groupby()` method and specifying a list of columns to group by. If there is only one column to be grouped, it can either be passed inside a list or by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88975f48-9fcd-48c4-b42c-56b01f13dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed1e15-f696-43be-ac0a-1a97940f111a",
   "metadata": {},
   "source": [
    "Notice that running the line above (the `.groupby()` method) didn't return back a dataframe; it returned a `DataFrameGroupBy` object. This object has partitioned out each of the rows of the dataframe into distinct groups (which we defined), but doesn't know exactly how they need to be aggregated just yet.\n",
    "\n",
    "Next, we will learn how to use aggregate functions on the `DataFrameGroupBy` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682b3d4-9a81-4aba-818c-57d5f9201822",
   "metadata": {},
   "source": [
    "### Aggregating the groups\n",
    "Aggregate functions can be run directly on the `DataFrameGroupBy` object. There are two ways to do so. The first way to run aggregations on groups is by using a dataframe method on a `DataFrameGroupBy` object (ie. `.sum()`). The second way is to use the `.agg()` method, passing in a dictionary of aggregations to perform.\n",
    "\n",
    "Personally, I prefer to use the `.agg()` method because it allows me to use mutliple aggregations at a time, but will also allow me to perform just a single aggregation too.\n",
    "\n",
    "#### Method 1: Dataframe methods\n",
    "\n",
    "The first way to use an aggregate function with `.groupby()` is by using a a built-in dataframe method to compute a single calculation across the dataframe. These built in aggregation methods include `.count()`, `.nunique()`, `.mean()`, `.median()`, and `.std()`.\n",
    "\n",
    "Note that the `.mode()` method can only be applied to a Series or dataframe, not to a `DataFrameGroupBy` object. Additionally, the `.max()` and `.min()` methods can only be applied to dataframes, Series, and `DataFrameGroupBy` objects that contain exclusively numerical data.\n",
    "\n",
    "##### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57510fa3-635e-4b21-bed1-d53ffd597f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06741561-8b32-457a-ab80-9baedfa4ba4c",
   "metadata": {},
   "source": [
    "##### Count distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66a0ce-a5c8-4d5a-b61b-560322458ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64259fd1-665e-4529-895e-600d14e5ca89",
   "metadata": {},
   "source": [
    "##### Mean (Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a52e57-b90e-4fdf-9ffd-0b3196f9cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197429f0-539f-43bb-9498-03d3b8d2b83b",
   "metadata": {},
   "source": [
    "##### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc93a3-173d-4eb3-a678-9c3d0a33662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae2eef9-a0e4-4c0b-b2a5-7d2c0140373a",
   "metadata": {},
   "source": [
    "##### Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370eb10e-1d01-4cd3-a988-adf52faee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b43714-88ba-4a5b-a5fa-94c625191d36",
   "metadata": {},
   "source": [
    "##### Max\n",
    "Note that the `.max()` method can only be applied to dataframes, Series, and `DataFrameGroupBy` objects that contain exclusively numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef39b80-d5ed-400e-8fed-cac6205a0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Pclass', 'Fare']].groupby(['Pclass']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10c672-8051-4675-9599-07da964ee662",
   "metadata": {},
   "source": [
    "##### Min\n",
    "Note that the `.min()` method can only be applied to dataframes, Series, and `DataFrameGroupBy` objects that contain exclusively numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c66916-07c2-4085-b01d-a51afa9eaf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Pclass', 'Fare']].groupby(['Pclass']).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad3c67-ac22-4f3d-ae41-15223cce7e6e",
   "metadata": {},
   "source": [
    "#### Method 2: The `.agg()` method\n",
    "\n",
    "`DataFrameGroupBy` objects can also have many aggregate functions applied to them at once. This can be done by applying the `.agg()` method, which is unique to `DataFrameGroupBy` objects.\n",
    "\n",
    "The `.agg()` method accepts a dictionary where each key is the field to be aggregated and the value attached to that key is the aggregation to be applied.\n",
    "\n",
    "You can apply the following aggregate functions to the groupby:\n",
    "\n",
    "| Key-word      | Description |\n",
    "| ----------- | ----------- |\n",
    "| `count`      | Count       |\n",
    "| `sum`   | Sum        |\n",
    "| `mean`      | Average (mean)       |\n",
    "| `median`   | Median        |\n",
    "| `nunique`      | Count Distinct       |\n",
    "| `min`   | Minimum (only works on numerical data)       |\n",
    "| `max`      | Maximum (only works on numerical data)    |\n",
    "| `std`      | Standard Deviation       |\n",
    "| `var`   | Variance        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f650807-9306-427a-beeb-90251bf1d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).agg({'Fare': 'median', 'Survived': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa58e496-7707-43bb-869b-e86f9afcb632",
   "metadata": {},
   "source": [
    "You can also switch out each value for a list of aggregations to compute for each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b20886-3c3a-41f3-b300-cba60c81e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Pclass']).agg({'Fare': ['median', 'mean'], 'Survived': ['mean', 'nunique']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
