{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fe9bd5-cd9b-4213-b192-33e82ba205e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3.1 Adding and Removing Rows and Columns\n",
    "\n",
    "When working with dataframes, sometimes we need to add or remove columns from the database. Perhaps you need to perform an calculation using two columns and want to store that calculation in a new column, or have too many irrelevant columns and need to reduce the size. Pandas easily lets the programmer add and remove columns.\n",
    "\n",
    "Adding and removing rows is easy too. Let's look at how it's done.\n",
    "\n",
    "### About the data\n",
    "\n",
    "The data used in this notebook shows information about passengers on the *Titanic* cruiseliner, a ship which set out from Southampton, U.K. to sail across the Atlantic ocean and which tragically sank upon collision with an iceberg. The dataset contains information about each passenger's passenger class, name, sex, age, siblings, parents/children, ticket number, ticket fare, cabin number, and the embarked location. It also contains information about each passenger's survival status. This data set is extremely popular among data scientists and will facilitate demonstrations of Pandas concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336dd72-d110-4f2a-b743-96372ec3aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb674aa-cd62-40b6-ab1e-988248cf8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038745c-e834-4319-9c6c-b9c98e07ccdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Adding Columns\n",
    "Adding columns is as simple as accessing a new column in the existing dataframe and assigning it a Series object, giving it its column name in the process. The Series has to be the same length as the number of rows in the dataframe. A new column can also be assigned a constant value.\n",
    "\n",
    "In other words, a new column is retrieved from the dataframe (even before it is created) in the format `df['newColumn']` and then it is assigned a Series.\n",
    "\n",
    "Usually, the new column is computed using an existing column, or several columns. In the code below, for example, a new column `FareRounded` is set to the values of the `Fare` column, after being rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c9cdd-9f34-4088-823a-863e60bfdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FareRounded'] = round(df['Fare'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d60290-30fb-4534-a791-4bd8372bb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ef18c-b0c4-483a-b85b-6f5244f382e3",
   "metadata": {},
   "source": [
    "You can even add more than one column at once by specifying a list of new columns and assigning them a dataframe with the same number of columns.\n",
    "\n",
    "In this example, we use the `.str` property and its accompanying `.split()` method to split each value in the `Name` column into two columns. Both columns are split by comma `,`. The argument to the `.split()` method `expand=True` turns the results into a dataframe, where everything on the left side of the comma (last name) is in the first column and everything on the right side of the comma (first name) is in the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297f4a9-685b-4e1a-8aed-5e91549f2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `.str.split()` method with expand=True splits a Series where each value is a list into one column per item in each list.\n",
    "names_df = df['Name'].str.split(\",\", expand=True)\n",
    "names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b78611-7fae-4561-ab7b-97619f89628d",
   "metadata": {},
   "source": [
    "Notice that the code above didn't modify the original dataframe, but instead created a new dataframe and assigned it to the variable `names_df`. The `expand=True` argument forced the `.split()` method to return a dataframe instead of a Series. Only a dataframe with two columns can be assigned to two columns in a dataframe simultaneously.\n",
    "\n",
    "Because a two-column dataframe was created above, we can create two columns at the same time by setting two columns equal to the `names_df` dataframe. We can create two columns at once by passing in a list of column names in the format `df[ [col1, col2] ]` and setting them equal to a dataframe with two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba07a4c-19a9-47d8-b43c-fd189502a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the two columns from the dataframe returned above to the current dataframe.\n",
    "df[['LastName', 'FirstMiddleName']] = names_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c8752-55b4-4dc0-ad51-3455fdf44d0a",
   "metadata": {},
   "source": [
    "Run the code below to see how the new columns were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412179f-9f50-47d1-aa1a-fb29d97d5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc982000-2efd-4dc0-998b-6c771669478f",
   "metadata": {},
   "source": [
    "### Removing columns\n",
    "\n",
    "If you want to get rid of a column, you can do so with the `.drop()` method. Note that this method does not change the original dataframe but instead returns a new dataframe. You can tell the method to modify the original dataframe by passing in `inplace=True`.\n",
    "\n",
    "You can drop a single column by passing in its name or multiple columns by passing in a list of column names. Note the need for the `columns` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c3da3-1797-48dc-920a-04333a91f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Cabin') # The column is dropped, but the original dataframe isn't changed.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e02b5f-2f89-46b3-ba2a-3ca52d1ac84e",
   "metadata": {},
   "source": [
    "The `inplace=True` argument modifies the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062eaab8-e6cf-4681-b1c9-14fd870eee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Cabin', 'Ticket'], inplace=True) # Multiple columns are dropped from the original dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26a03f-c730-4faa-b485-0a640d31ef2f",
   "metadata": {},
   "source": [
    "### Adding rows\n",
    "Adding rows isn't something you will typically do in Pandas, since data will likely be provided for you in the data file or database. Sometimes, however, you may have data coming from other sources that need to be combined into a single dataframe.\n",
    "\n",
    "The `concat()` function is a **Pandas function** (not a dataframe method) that takes in a list of dataframe or Series objects and puts them on top of each other. The data to be added *must* be either a dataframe or a Series. Because Series usually represent a single column, I would advise that new data be converted to a *dataframe* before it is concatted to the original dataframe.\n",
    "\n",
    "This means that if new data is defined as a dictionary (as seen below), it should be reformatted and then converted to a dataframe with the `DataFrame()` function.\n",
    "\n",
    "Pass in `ignore_index=True` to the `concat()` function to give each row a unique named index and not keep their original named index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228d708-6963-4e3b-8ecd-0d3a4ff068f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_titanic_passenger = { # Notice that not all fields have to be defined.\n",
    "    'PassengerId': [999],\n",
    "    'Survived': [1],\n",
    "    'Pclass':3,\n",
    "    'Name': ['Vespucci, Mr. Amerigo'],\n",
    "    'Sex': ['male'],\n",
    "    'Age': [57]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_titanic_passenger)\n",
    "\n",
    "df = pd.concat([df, new_df], ignore_index=True) # ignore_index=True makes the data reset the named\n",
    "                                                # index numbers-- remove it to see what happens!\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6779cc6b-9fbc-4751-9be6-74d7690ea918",
   "metadata": {},
   "source": [
    "### Removing Rows\n",
    "\n",
    "You can remove rows from a dataframe in the same way that you remove columns, with the `.drop()` method. This time, however, you will pass in a single index or a list of named row indexes to the `index` argument. Note again that the original dataframe isn't modified unless we pass in the argument `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfa181-3500-47b2-a77e-469752d9d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=891) # Dropping a single row whose named index is 891, but not saving to original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c5b24-8856-4cb7-93de-4459e33b511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[0, 1, 2]) # Dropping several rows by passing in a list of indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9bf3c-d735-47eb-9021-f6cdd67762bf",
   "metadata": {},
   "source": [
    "You can access the indexes of each row in a dataframe with the `.index` property. This is useful when dropping rows based on a condition or filter.\n",
    "\n",
    "In the code below, for example, a filter called `filt` is created which returns a Series of `True`/`False` values where `Pclass` is 3. Then, a variable called `indexes_to_drop` is created that has the filtered dataframe and the indexes of each row. This Series of indexes can then be passed into the `index` argument of the `.drop()` method to drop only rows where `Pclass` is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff671410-275c-44d0-867c-bc35ed8215d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filt = df['Pclass'] == 3\n",
    "indexes_to_drop = df[filt].index\n",
    "df.drop(index=indexes_to_drop, inplace=True) # Overriding original dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55377f49-ee86-48ed-a28a-b45ea4be65c8",
   "metadata": {},
   "source": [
    "Powerfully, we can also combine the code above into a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbcd78-cc6a-43f9-a43e-51aa8797e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df[ df['Pclass'] == 3 ].index, inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
